{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loading dataset"
      ],
      "metadata": {
        "id": "BMqAjKlmL1Gc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdZtciiMpZIb"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM5ckDTqpymq",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c santander-customer-transaction-prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zls24Ljdpz-n",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!unzip santander-customer-transaction-prediction.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install optuna"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oxVv9RmTUtKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iaE8TlBOsSq7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "import optuna\n",
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "7F6J0xntsQxh",
        "outputId": "11206ebe-5520-4423-8625-2e897cbaf5f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
              "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
              "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
              "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
              "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
              "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
              "\n",
              "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
              "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
              "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
              "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
              "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
              "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
              "\n",
              "   var_196  var_197  var_198  var_199  \n",
              "0   7.8784   8.5635  12.7803  -1.0914  \n",
              "1   8.1267   8.7889  18.3560   1.9518  \n",
              "2  -6.5213   8.2675  14.7222   0.3965  \n",
              "3  -2.9275  10.2922  17.9697  -8.9996  \n",
              "4   3.9267   9.5031  17.9974  -8.8104  \n",
              "\n",
              "[5 rows x 202 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50bac697-09d7-480a-82a5-e7443671ca09\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID_code</th>\n",
              "      <th>target</th>\n",
              "      <th>var_0</th>\n",
              "      <th>var_1</th>\n",
              "      <th>var_2</th>\n",
              "      <th>var_3</th>\n",
              "      <th>var_4</th>\n",
              "      <th>var_5</th>\n",
              "      <th>var_6</th>\n",
              "      <th>var_7</th>\n",
              "      <th>...</th>\n",
              "      <th>var_190</th>\n",
              "      <th>var_191</th>\n",
              "      <th>var_192</th>\n",
              "      <th>var_193</th>\n",
              "      <th>var_194</th>\n",
              "      <th>var_195</th>\n",
              "      <th>var_196</th>\n",
              "      <th>var_197</th>\n",
              "      <th>var_198</th>\n",
              "      <th>var_199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.9255</td>\n",
              "      <td>-6.7863</td>\n",
              "      <td>11.9081</td>\n",
              "      <td>5.0930</td>\n",
              "      <td>11.4607</td>\n",
              "      <td>-9.2834</td>\n",
              "      <td>5.1187</td>\n",
              "      <td>18.6266</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4354</td>\n",
              "      <td>3.9642</td>\n",
              "      <td>3.1364</td>\n",
              "      <td>1.6910</td>\n",
              "      <td>18.5227</td>\n",
              "      <td>-2.3978</td>\n",
              "      <td>7.8784</td>\n",
              "      <td>8.5635</td>\n",
              "      <td>12.7803</td>\n",
              "      <td>-1.0914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>0</td>\n",
              "      <td>11.5006</td>\n",
              "      <td>-4.1473</td>\n",
              "      <td>13.8588</td>\n",
              "      <td>5.3890</td>\n",
              "      <td>12.3622</td>\n",
              "      <td>7.0433</td>\n",
              "      <td>5.6208</td>\n",
              "      <td>16.5338</td>\n",
              "      <td>...</td>\n",
              "      <td>7.6421</td>\n",
              "      <td>7.7214</td>\n",
              "      <td>2.5837</td>\n",
              "      <td>10.9516</td>\n",
              "      <td>15.4305</td>\n",
              "      <td>2.0339</td>\n",
              "      <td>8.1267</td>\n",
              "      <td>8.7889</td>\n",
              "      <td>18.3560</td>\n",
              "      <td>1.9518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>0</td>\n",
              "      <td>8.6093</td>\n",
              "      <td>-2.7457</td>\n",
              "      <td>12.0805</td>\n",
              "      <td>7.8928</td>\n",
              "      <td>10.5825</td>\n",
              "      <td>-9.0837</td>\n",
              "      <td>6.9427</td>\n",
              "      <td>14.6155</td>\n",
              "      <td>...</td>\n",
              "      <td>2.9057</td>\n",
              "      <td>9.7905</td>\n",
              "      <td>1.6704</td>\n",
              "      <td>1.6858</td>\n",
              "      <td>21.6042</td>\n",
              "      <td>3.1417</td>\n",
              "      <td>-6.5213</td>\n",
              "      <td>8.2675</td>\n",
              "      <td>14.7222</td>\n",
              "      <td>0.3965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0604</td>\n",
              "      <td>-2.1518</td>\n",
              "      <td>8.9522</td>\n",
              "      <td>7.1957</td>\n",
              "      <td>12.5846</td>\n",
              "      <td>-1.8361</td>\n",
              "      <td>5.8428</td>\n",
              "      <td>14.9250</td>\n",
              "      <td>...</td>\n",
              "      <td>4.4666</td>\n",
              "      <td>4.7433</td>\n",
              "      <td>0.7178</td>\n",
              "      <td>1.4214</td>\n",
              "      <td>23.0347</td>\n",
              "      <td>-1.2706</td>\n",
              "      <td>-2.9275</td>\n",
              "      <td>10.2922</td>\n",
              "      <td>17.9697</td>\n",
              "      <td>-8.9996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>0</td>\n",
              "      <td>9.8369</td>\n",
              "      <td>-1.4834</td>\n",
              "      <td>12.8746</td>\n",
              "      <td>6.6375</td>\n",
              "      <td>12.2772</td>\n",
              "      <td>2.4486</td>\n",
              "      <td>5.9405</td>\n",
              "      <td>19.2514</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.4905</td>\n",
              "      <td>9.5214</td>\n",
              "      <td>-0.1508</td>\n",
              "      <td>9.1942</td>\n",
              "      <td>13.2876</td>\n",
              "      <td>-1.5121</td>\n",
              "      <td>3.9267</td>\n",
              "      <td>9.5031</td>\n",
              "      <td>17.9974</td>\n",
              "      <td>-8.8104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 202 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50bac697-09d7-480a-82a5-e7443671ca09')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-50bac697-09d7-480a-82a5-e7443671ca09 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-50bac697-09d7-480a-82a5-e7443671ca09');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3c32944e-5429-45ec-aa05-7b4acd21d7d6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c32944e-5429-45ec-aa05-7b4acd21d7d6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3c32944e-5429-45ec-aa05-7b4acd21d7d6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#Loading the training dataset\n",
        "data = pd.read_csv('train.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIuviVmZskFc",
        "outputId": "96637a1d-a641-42c7-f057-1bc9e06d5f93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 202)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG1LshMAsm_9",
        "outputId": "636d8003-e74d-4bc5-9f2a-b3ea283bc3fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200000 entries, 0 to 199999\n",
            "Columns: 202 entries, ID_code to var_199\n",
            "dtypes: float64(200), int64(1), object(1)\n",
            "memory usage: 308.2+ MB\n",
            "None\n",
            "\n",
            "Null Values in the Dataset:\n",
            "No null values found in the dataset.\n"
          ]
        }
      ],
      "source": [
        "#Displaying info of the dataset\n",
        "print(\"Dataset Info:\")\n",
        "print(data.info())\n",
        "\n",
        "#Checking for null values in the dataset\n",
        "print(\"\\nNull Values in the Dataset:\")\n",
        "null_values = data.isnull().sum()\n",
        "if null_values.sum() == 0:\n",
        "  print(\"No null values found in the dataset.\")\n",
        "else:\n",
        "  print(null_values[null_values > 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering"
      ],
      "metadata": {
        "id": "2Le5sUIRMGun"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6StNSYiDspHQ"
      },
      "outputs": [],
      "source": [
        "#Dropping the 'ID_code' column from the DataFrame as it is not required\n",
        "data = data.drop('ID_code', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "a2n0peEisra6"
      },
      "outputs": [],
      "source": [
        "#Selecting numerical features\n",
        "features = data.drop('target', axis=1)\n",
        "\n",
        "#Standardizing the features\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "YqymuCr6stZb",
        "outputId": "49cfb4a5-7f96-44f7-fac5-82224ca4f2f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Applying PCA\n",
        "pca = PCA().fit(features_scaled)\n",
        "\n",
        "#Plotting the Cumulative Summation of the Explained Variance\n",
        "plt.figure()\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Variance (%)')  # for each component\n",
        "plt.title('Explained Variance')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#Choosing the number of components e.g., 95% variance\n",
        "pca = PCA(n_components=0.95)\n",
        "principalComponents = pca.fit_transform(features_scaled)\n",
        "\n",
        "#Creating a DataFrame with the principal components\n",
        "principalDf = pd.DataFrame(data = principalComponents, columns = [f'Principal Component {i}' for i in range(principalComponents.shape[1])])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mTxpVw-swAX",
        "outputId": "8d1dfbf4-2030-4633-de6f-d127d2c26c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of components selected: 190\n"
          ]
        }
      ],
      "source": [
        "#Printing the number of components\n",
        "print(\"Number of components selected:\", pca.n_components_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting Data"
      ],
      "metadata": {
        "id": "YoJOAElDNyZ7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Or_-RBMCtJ4j"
      },
      "outputs": [],
      "source": [
        "#Merging the data\n",
        "df = pd.concat([data['target'], principalDf], axis=1)\n",
        "df.columns = df.columns.str.replace(' ', '_', regex=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMAvZ5eLtMPC",
        "outputId": "18314baa-81a1-452e-fb2d-6d27b7495e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 120000 samples\n",
            "Validation set size: 40000 samples\n",
            "Testing set size: 40000 samples\n"
          ]
        }
      ],
      "source": [
        "#Splitting data into features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "#Splitting the data into training and remaining data first\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "#Splitting the remaining data into validation and testing sets\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Validation set size: {X_val.shape[0]} samples\")\n",
        "print(f\"Testing set size: {X_test.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline Models"
      ],
      "metadata": {
        "id": "W0Qx9dq-N2cb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7bOtkB3tOAG",
        "outputId": "99ba75d2-8ca8-4c8b-986b-996f878b2537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression ROC-AUC: 0.8631566540490646\n",
            "Decision Tree ROC-AUC: 0.6317903585863518\n"
          ]
        }
      ],
      "source": [
        "#Initialize the logistic regression model\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "#Predicting on validation set\n",
        "y_val_pred_log_reg = log_reg.predict_proba(X_val)[:, 1]\n",
        "\n",
        "#Evaluating the model\n",
        "log_reg_auc = roc_auc_score(y_val, y_val_pred_log_reg)\n",
        "\n",
        "#Initializing the decision tree model\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "#Predicting on validation set\n",
        "y_val_pred_tree = decision_tree.predict_proba(X_val)[:, 1]\n",
        "\n",
        "#Evaluating the model\n",
        "tree_auc = roc_auc_score(y_val, y_val_pred_tree)\n",
        "\n",
        "print(f'Logistic Regression ROC-AUC: {log_reg_auc}')\n",
        "print(f'Decision Tree ROC-AUC: {tree_auc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "je06OkY-utBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5a0baf-3f11-47e3-a170-3b4c4ca126ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:35:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "# Initialize and fit XGBoost\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "xgb.fit(X_train, y_train)\n",
        "# Predict on validation set\n",
        "y_val_pred_xgb = xgb.predict_proba(X_val)[:, 1]\n",
        "# Evaluate the model\n",
        "xgb_auc = roc_auc_score(y_val, y_val_pred_xgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCuEr6SCutqe",
        "outputId": "921a1314-2da1-4c20-cd33-cc901e68b17a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025066 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "XGBoost ROC-AUC: 0.8528763506152468\n",
            "LightGBM ROC-AUC: 0.8643179155501046\n"
          ]
        }
      ],
      "source": [
        "#Initializing and fitting LightGBM\n",
        "lgbm = LGBMClassifier()\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "#Predicting on validation set\n",
        "y_val_pred_lgbm = lgbm.predict_proba(X_val)[:, 1]\n",
        "\n",
        "#Evaluating the model\n",
        "lgbm_auc = roc_auc_score(y_val, y_val_pred_lgbm)\n",
        "\n",
        "print(f'XGBoost ROC-AUC: {xgb_auc}')\n",
        "print(f'LightGBM ROC-AUC: {lgbm_auc}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "qitQ7NyhR2WZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    # Hyperparameters to tune using the updated API\n",
        "    param = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'auc',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.2, log=True),\n",
        "        'n_estimators': 1000\n",
        "    }\n",
        "\n",
        "    # Creating the LightGBM datasets\n",
        "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
        "    dvalid = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "    # Model training\n",
        "    gbm = lgb.train(param, dtrain, valid_sets=[dvalid], callbacks=[lgb.early_stopping(10), lgb.log_evaluation(100)])\n",
        "\n",
        "    # Validation prediction\n",
        "    preds = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
        "\n",
        "    # Compute ROC-AUC score\n",
        "    roc_auc = roc_auc_score(y_val, preds)\n",
        "    return roc_auc\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Best hyperparameters\n",
        "print('Best trial:', study.best_trial.params)\n",
        "print('Best score:', study.best_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O66IWQ65R1hP",
        "outputId": "841e6e66-7dbb-4dfd-9e2d-63c855d9ca90"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:41:16,734] A new study created in memory with name: no-name-10d20b8b-f70b-47c4-ad26-2ac6801effd2\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.136621 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.864848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:41:23,694] Trial 0 finished with value: 0.8654990830135871 and parameters: {'lambda_l1': 1.1661928367209413, 'lambda_l2': 2.495842030678867, 'num_leaves': 87, 'feature_fraction': 0.8218513796224716, 'bagging_fraction': 0.40518722424289516, 'bagging_freq': 5, 'min_child_samples': 88, 'learning_rate': 0.062248876064170164}. Best is trial 0 with value: 0.8654990830135871.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[122]\tvalid_0's auc: 0.865499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061530 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:41:25,139] Trial 1 finished with value: 0.8613163925924444 and parameters: {'lambda_l1': 0.16453455081166263, 'lambda_l2': 0.0002531102084518325, 'num_leaves': 7, 'feature_fraction': 0.7624272022612932, 'bagging_fraction': 0.46947490330596714, 'bagging_freq': 3, 'min_child_samples': 67, 'learning_rate': 0.056793701533140006}. Best is trial 0 with value: 0.8654990830135871.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[19]\tvalid_0's auc: 0.861316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064285 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[100]\tvalid_0's auc: 0.862753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:41:37,439] Trial 2 finished with value: 0.8627832691639263 and parameters: {'lambda_l1': 6.416405109765633, 'lambda_l2': 7.707809631458456e-07, 'num_leaves': 138, 'feature_fraction': 0.6165956608251744, 'bagging_fraction': 0.6354413831085205, 'bagging_freq': 2, 'min_child_samples': 51, 'learning_rate': 0.0019037819265184405}. Best is trial 0 with value: 0.8654990830135871.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[99]\tvalid_0's auc: 0.862783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060154 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.864595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:41:45,663] Trial 3 finished with value: 0.8669781786775856 and parameters: {'lambda_l1': 1.8936244794659034e-08, 'lambda_l2': 0.35245677018092925, 'num_leaves': 119, 'feature_fraction': 0.6029441089307555, 'bagging_fraction': 0.418521291912712, 'bagging_freq': 4, 'min_child_samples': 95, 'learning_rate': 0.037056922929527544}. Best is trial 3 with value: 0.8669781786775856.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[177]\tvalid_0's auc: 0.866978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109766 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.864548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:41:55,594] Trial 4 finished with value: 0.8661023576573702 and parameters: {'lambda_l1': 7.317579481449548e-06, 'lambda_l2': 1.160760335482163e-07, 'num_leaves': 21, 'feature_fraction': 0.8138295306613405, 'bagging_fraction': 0.6792051035009901, 'bagging_freq': 7, 'min_child_samples': 81, 'learning_rate': 0.05192737576604932}. Best is trial 3 with value: 0.8669781786775856.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[164]\tvalid_0's auc: 0.866102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062220 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:41:58,697] Trial 5 finished with value: 0.8632123149772646 and parameters: {'lambda_l1': 4.2090923988999914e-07, 'lambda_l2': 6.868857135663675, 'num_leaves': 46, 'feature_fraction': 0.7446090338161064, 'bagging_fraction': 0.5712445808616067, 'bagging_freq': 2, 'min_child_samples': 66, 'learning_rate': 0.03096993354331048}. Best is trial 3 with value: 0.8669781786775856.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[65]\tvalid_0's auc: 0.863212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095040 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.865734\n",
            "[200]\tvalid_0's auc: 0.86726\n",
            "[300]\tvalid_0's auc: 0.869079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:42:34,000] Trial 6 finished with value: 0.8702032476598389 and parameters: {'lambda_l1': 6.242471157880766e-06, 'lambda_l2': 0.022894066047817394, 'num_leaves': 175, 'feature_fraction': 0.6793013068525424, 'bagging_fraction': 0.559109728966536, 'bagging_freq': 2, 'min_child_samples': 91, 'learning_rate': 0.01273207284211691}. Best is trial 6 with value: 0.8702032476598389.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[369]\tvalid_0's auc: 0.870203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059889 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.865988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:42:47,192] Trial 7 finished with value: 0.8686393071358516 and parameters: {'lambda_l1': 1.4564953021391439e-07, 'lambda_l2': 0.21185672313732917, 'num_leaves': 63, 'feature_fraction': 0.7241792518368744, 'bagging_fraction': 0.6700413848343296, 'bagging_freq': 3, 'min_child_samples': 83, 'learning_rate': 0.05229968742336427}. Best is trial 6 with value: 0.8702032476598389.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[183]\tvalid_0's auc: 0.868639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059829 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.865826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:43:00,490] Trial 8 finished with value: 0.8659269441122057 and parameters: {'lambda_l1': 2.0506057992245985, 'lambda_l2': 0.0027788475414693647, 'num_leaves': 124, 'feature_fraction': 0.6107119268264563, 'bagging_fraction': 0.570936977237213, 'bagging_freq': 3, 'min_child_samples': 95, 'learning_rate': 0.07174871207450974}. Best is trial 6 with value: 0.8702032476598389.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[108]\tvalid_0's auc: 0.865927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060523 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.861309\n",
            "[200]\tvalid_0's auc: 0.862401\n",
            "[300]\tvalid_0's auc: 0.863101\n",
            "[400]\tvalid_0's auc: 0.863982\n",
            "[500]\tvalid_0's auc: 0.864748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:43:08,472] Trial 9 finished with value: 0.8652195729942378 and parameters: {'lambda_l1': 1.0228912599618541e-06, 'lambda_l2': 4.082710560420335e-06, 'num_leaves': 3, 'feature_fraction': 0.7789603817157935, 'bagging_fraction': 0.4387281498825649, 'bagging_freq': 4, 'min_child_samples': 15, 'learning_rate': 0.030355712395568432}. Best is trial 6 with value: 0.8702032476598389.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[567]\tvalid_0's auc: 0.86522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063193 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:43:19,271] Trial 10 finished with value: 0.8612294331544383 and parameters: {'lambda_l1': 0.00070523709390253, 'lambda_l2': 0.002765197339416768, 'num_leaves': 225, 'feature_fraction': 0.9898360141789634, 'bagging_fraction': 0.8724291279352178, 'bagging_freq': 1, 'min_child_samples': 32, 'learning_rate': 0.005706702624741017}. Best is trial 6 with value: 0.8702032476598389.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[37]\tvalid_0's auc: 0.861229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020080 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:43:20,913] Trial 11 finished with value: 0.8539780044349796 and parameters: {'lambda_l1': 0.00020008846481837716, 'lambda_l2': 0.033785638060687184, 'num_leaves': 189, 'feature_fraction': 0.5348675518587608, 'bagging_fraction': 0.8182553225268363, 'bagging_freq': 1, 'min_child_samples': 74, 'learning_rate': 0.19707547905388048}. Best is trial 6 with value: 0.8702032476598389.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.853978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020577 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863258\n",
            "[200]\tvalid_0's auc: 0.865743\n",
            "[300]\tvalid_0's auc: 0.867106\n",
            "[400]\tvalid_0's auc: 0.868002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:43:58,390] Trial 12 finished with value: 0.8680815406906353 and parameters: {'lambda_l1': 1.6248938440893698e-08, 'lambda_l2': 0.1049323126312107, 'num_leaves': 180, 'feature_fraction': 0.4679334898028028, 'bagging_fraction': 0.973975771133123, 'bagging_freq': 6, 'min_child_samples': 55, 'learning_rate': 0.009950975570957468}. Best is trial 6 with value: 0.8702032476598389.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[411]\tvalid_0's auc: 0.868082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061040 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.861823\n",
            "[200]\tvalid_0's auc: 0.863642\n",
            "[300]\tvalid_0's auc: 0.865005\n",
            "[400]\tvalid_0's auc: 0.866384\n",
            "[500]\tvalid_0's auc: 0.867397\n",
            "[600]\tvalid_0's auc: 0.868294\n",
            "[700]\tvalid_0's auc: 0.868976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:44:42,340] Trial 13 finished with value: 0.8693119702452561 and parameters: {'lambda_l1': 2.5660825751348567e-05, 'lambda_l2': 6.25828923197494e-05, 'num_leaves': 63, 'feature_fraction': 0.9741914206010079, 'bagging_fraction': 0.7696863952480321, 'bagging_freq': 3, 'min_child_samples': 100, 'learning_rate': 0.011857310429094929}. Best is trial 6 with value: 0.8702032476598389.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[748]\tvalid_0's auc: 0.869312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059904 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.86256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:44:59,339] Trial 14 finished with value: 0.8631920336255651 and parameters: {'lambda_l1': 8.694955766355395e-05, 'lambda_l2': 4.6502000863131936e-05, 'num_leaves': 171, 'feature_fraction': 0.9530766327896257, 'bagging_fraction': 0.7761425065367294, 'bagging_freq': 2, 'min_child_samples': 100, 'learning_rate': 0.004871457253777264}. Best is trial 6 with value: 0.8702032476598389.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[151]\tvalid_0's auc: 0.863192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061592 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.864328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:45:18,103] Trial 15 finished with value: 0.865491265274012 and parameters: {'lambda_l1': 0.0032699380829874797, 'lambda_l2': 1.7185163600159545e-05, 'num_leaves': 254, 'feature_fraction': 0.8711324801734072, 'bagging_fraction': 0.7596544400531581, 'bagging_freq': 5, 'min_child_samples': 41, 'learning_rate': 0.014273095499294192}. Best is trial 6 with value: 0.8702032476598389.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[148]\tvalid_0's auc: 0.865491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064340 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.86184\n",
            "Early stopping, best iteration is:\n",
            "[94]\tvalid_0's auc: 0.8619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:45:22,511] Trial 16 finished with value: 0.8619001573266709 and parameters: {'lambda_l1': 0.010761973538317947, 'lambda_l2': 0.0032506142330585392, 'num_leaves': 89, 'feature_fraction': 0.8967364209204991, 'bagging_fraction': 0.5323827895523007, 'bagging_freq': 2, 'min_child_samples': 78, 'learning_rate': 0.0010296881907870248}. Best is trial 6 with value: 0.8702032476598389.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096349 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:45:36,822] Trial 17 finished with value: 0.8639459289038508 and parameters: {'lambda_l1': 1.7619750690025074e-05, 'lambda_l2': 0.0002788734112273195, 'num_leaves': 156, 'feature_fraction': 0.6680613520989372, 'bagging_fraction': 0.8778588113688347, 'bagging_freq': 3, 'min_child_samples': 6, 'learning_rate': 0.013122199060532117}. Best is trial 6 with value: 0.8702032476598389.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[123]\tvalid_0's auc: 0.863946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059277 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:45:49,472] Trial 18 finished with value: 0.8635362931258628 and parameters: {'lambda_l1': 5.537040609392802e-06, 'lambda_l2': 0.011893949060664806, 'num_leaves': 200, 'feature_fraction': 0.6825068734975872, 'bagging_fraction': 0.6202467560576342, 'bagging_freq': 1, 'min_child_samples': 90, 'learning_rate': 0.004678229084545269}. Best is trial 6 with value: 0.8702032476598389.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[72]\tvalid_0's auc: 0.863536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018211 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.865286\n",
            "[200]\tvalid_0's auc: 0.868305\n",
            "[300]\tvalid_0's auc: 0.869594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:46:11,095] Trial 19 finished with value: 0.870497435743536 and parameters: {'lambda_l1': 3.353779821468619e-05, 'lambda_l2': 3.370359244126943e-08, 'num_leaves': 99, 'feature_fraction': 0.43615050147021267, 'bagging_fraction': 0.7308874099371419, 'bagging_freq': 4, 'min_child_samples': 100, 'learning_rate': 0.019478526594411596}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[367]\tvalid_0's auc: 0.870497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019057 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:46:12,756] Trial 20 finished with value: 0.8564927129609602 and parameters: {'lambda_l1': 0.026476778700636243, 'lambda_l2': 1.522819157108943e-08, 'num_leaves': 100, 'feature_fraction': 0.42896960343296936, 'bagging_fraction': 0.5043401873521207, 'bagging_freq': 5, 'min_child_samples': 70, 'learning_rate': 0.021576631829333098}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[7]\tvalid_0's auc: 0.856493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020096 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:46:23,004] Trial 21 finished with value: 0.863293254411404 and parameters: {'lambda_l1': 5.4765930056466387e-05, 'lambda_l2': 1.6800973468557792e-08, 'num_leaves': 62, 'feature_fraction': 0.5148147892584883, 'bagging_fraction': 0.7479340091507435, 'bagging_freq': 4, 'min_child_samples': 99, 'learning_rate': 0.008151859987028795}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[71]\tvalid_0's auc: 0.863293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020969 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.864747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:46:30,450] Trial 22 finished with value: 0.8656389826686637 and parameters: {'lambda_l1': 0.0007946703694500671, 'lambda_l2': 1.097349366014455e-06, 'num_leaves': 146, 'feature_fraction': 0.533373913688828, 'bagging_fraction': 0.7279689173264517, 'bagging_freq': 4, 'min_child_samples': 87, 'learning_rate': 0.018679544022762316}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[128]\tvalid_0's auc: 0.865639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047542 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:46:39,666] Trial 23 finished with value: 0.8620096986670535 and parameters: {'lambda_l1': 2.0762700562589186e-06, 'lambda_l2': 5.866942331530519e-05, 'num_leaves': 106, 'feature_fraction': 0.41554232695597254, 'bagging_fraction': 0.8449612164724765, 'bagging_freq': 3, 'min_child_samples': 100, 'learning_rate': 0.0028735360853146645}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[63]\tvalid_0's auc: 0.86201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064575 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:46:41,950] Trial 24 finished with value: 0.8605152017116978 and parameters: {'lambda_l1': 3.388727229603925e-05, 'lambda_l2': 2.087685058324794e-07, 'num_leaves': 43, 'feature_fraction': 0.9141334503164049, 'bagging_fraction': 0.9204352710035834, 'bagging_freq': 2, 'min_child_samples': 90, 'learning_rate': 0.00800439092769981}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[34]\tvalid_0's auc: 0.860515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061752 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863775\n",
            "[200]\tvalid_0's auc: 0.865787\n",
            "Early stopping, best iteration is:\n",
            "[196]\tvalid_0's auc: 0.865841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:46:56,177] Trial 25 finished with value: 0.8658405632558069 and parameters: {'lambda_l1': 1.5588406451717234e-07, 'lambda_l2': 0.0008017895564027865, 'num_leaves': 72, 'feature_fraction': 0.6512835281507078, 'bagging_fraction': 0.7015035496056146, 'bagging_freq': 4, 'min_child_samples': 62, 'learning_rate': 0.020052187279779792}. Best is trial 19 with value: 0.870497435743536.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023458 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:46:58,966] Trial 26 finished with value: 0.8598945214045612 and parameters: {'lambda_l1': 5.244011448230505e-06, 'lambda_l2': 0.0222019193551679, 'num_leaves': 160, 'feature_fraction': 0.5667776212281008, 'bagging_fraction': 0.7977441177464799, 'bagging_freq': 6, 'min_child_samples': 79, 'learning_rate': 0.11034132811572177}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[26]\tvalid_0's auc: 0.859895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020034 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.865671\n",
            "[200]\tvalid_0's auc: 0.868553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:47:29,872] Trial 27 finished with value: 0.8701062456982199 and parameters: {'lambda_l1': 0.0005037087147289566, 'lambda_l2': 6.348220838324549e-06, 'num_leaves': 204, 'feature_fraction': 0.4671337914168776, 'bagging_fraction': 0.6383966239005852, 'bagging_freq': 3, 'min_child_samples': 92, 'learning_rate': 0.012107682029398537}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[272]\tvalid_0's auc: 0.870106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021426 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:47:35,859] Trial 28 finished with value: 0.8653426111281866 and parameters: {'lambda_l1': 0.002399865624449118, 'lambda_l2': 8.003866382603569e-08, 'num_leaves': 207, 'feature_fraction': 0.47104120516625103, 'bagging_fraction': 0.6181950810325442, 'bagging_freq': 5, 'min_child_samples': 92, 'learning_rate': 0.003407176229252939}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[85]\tvalid_0's auc: 0.865343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027445 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.864552\n",
            "[200]\tvalid_0's auc: 0.867334\n",
            "[300]\tvalid_0's auc: 0.869253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:48:09,436] Trial 29 finished with value: 0.8695999385766747 and parameters: {'lambda_l1': 0.0002936388317336534, 'lambda_l2': 5.050748937341458e-06, 'num_leaves': 227, 'feature_fraction': 0.4638755598345277, 'bagging_fraction': 0.5709022212895307, 'bagging_freq': 5, 'min_child_samples': 85, 'learning_rate': 0.0071408858899301006}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[329]\tvalid_0's auc: 0.8696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023284 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.866392\n",
            "[200]\tvalid_0's auc: 0.86949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:48:37,574] Trial 30 finished with value: 0.8695442845363506 and parameters: {'lambda_l1': 0.05785382508082231, 'lambda_l2': 1.4790008325096757, 'num_leaves': 256, 'feature_fraction': 0.40803011206367, 'bagging_fraction': 0.5200248643004415, 'bagging_freq': 2, 'min_child_samples': 75, 'learning_rate': 0.022937431669734477}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[198]\tvalid_0's auc: 0.869544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025035 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.865388\n",
            "[200]\tvalid_0's auc: 0.867983\n",
            "[300]\tvalid_0's auc: 0.869593\n",
            "Early stopping, best iteration is:\n",
            "[307]\tvalid_0's auc: 0.869775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:49:09,910] Trial 31 finished with value: 0.869775131709798 and parameters: {'lambda_l1': 0.00016200805242195317, 'lambda_l2': 5.249819623627301e-06, 'num_leaves': 230, 'feature_fraction': 0.47418263985286974, 'bagging_fraction': 0.5773024669921758, 'bagging_freq': 5, 'min_child_samples': 84, 'learning_rate': 0.00931492466405104}. Best is trial 19 with value: 0.870497435743536.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026737 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:49:11,613] Trial 32 finished with value: 0.851238014139584 and parameters: {'lambda_l1': 0.00015840696988427133, 'lambda_l2': 5.656823924645342e-07, 'num_leaves': 226, 'feature_fraction': 0.496580706732744, 'bagging_fraction': 0.6454374270757368, 'bagging_freq': 6, 'min_child_samples': 87, 'learning_rate': 0.014744324832590758}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's auc: 0.851238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020914 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.865783\n",
            "[200]\tvalid_0's auc: 0.867741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:49:31,843] Trial 33 finished with value: 0.8679243731297306 and parameters: {'lambda_l1': 0.000908296235406178, 'lambda_l2': 5.5184003937942395e-06, 'num_leaves': 214, 'feature_fraction': 0.5731221182938451, 'bagging_fraction': 0.5885754113720832, 'bagging_freq': 4, 'min_child_samples': 94, 'learning_rate': 0.009387623691790616}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[213]\tvalid_0's auc: 0.867924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018828 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:49:45,066] Trial 34 finished with value: 0.8665484854038772 and parameters: {'lambda_l1': 1.1880046152970592e-05, 'lambda_l2': 3.019554472006529e-08, 'num_leaves': 240, 'feature_fraction': 0.4554349229818189, 'bagging_fraction': 0.4638568519292672, 'bagging_freq': 3, 'min_child_samples': 84, 'learning_rate': 0.016991487615776256}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[81]\tvalid_0's auc: 0.866548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020721 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.864946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:50:03,162] Trial 35 finished with value: 0.8664941193964173 and parameters: {'lambda_l1': 0.004574331169474536, 'lambda_l2': 1.690569846075581e-06, 'num_leaves': 196, 'feature_fraction': 0.5825670382953606, 'bagging_fraction': 0.711636666593058, 'bagging_freq': 5, 'min_child_samples': 56, 'learning_rate': 0.03727796231629199}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[162]\tvalid_0's auc: 0.866494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025479 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:50:05,163] Trial 36 finished with value: 0.8533510596043682 and parameters: {'lambda_l1': 1.1038198487686501e-06, 'lambda_l2': 3.416508567939597e-07, 'num_leaves': 167, 'feature_fraction': 0.49065419384058057, 'bagging_fraction': 0.6651763677682703, 'bagging_freq': 6, 'min_child_samples': 71, 'learning_rate': 0.027678652810608183}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[7]\tvalid_0's auc: 0.853351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024092 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863919\n",
            "[200]\tvalid_0's auc: 0.866272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:50:21,395] Trial 37 finished with value: 0.8663416700307629 and parameters: {'lambda_l1': 0.33905713166086515, 'lambda_l2': 1.3058865873406687e-05, 'num_leaves': 143, 'feature_fraction': 0.4399693840347111, 'bagging_fraction': 0.48214069015711825, 'bagging_freq': 4, 'min_child_samples': 63, 'learning_rate': 0.0034972593964579216}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[199]\tvalid_0's auc: 0.866342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027485 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.862749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:50:36,415] Trial 38 finished with value: 0.8639320498331512 and parameters: {'lambda_l1': 9.534988942201344e-05, 'lambda_l2': 4.9846463733995964e-08, 'num_leaves': 185, 'feature_fraction': 0.5349520336359882, 'bagging_fraction': 0.5972332303778816, 'bagging_freq': 7, 'min_child_samples': 48, 'learning_rate': 0.006241493665231535}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[137]\tvalid_0's auc: 0.863932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061651 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.866546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:50:52,256] Trial 39 finished with value: 0.8686980676083768 and parameters: {'lambda_l1': 7.163895368073367e-08, 'lambda_l2': 0.0009551490945594565, 'num_leaves': 118, 'feature_fraction': 0.644089380748715, 'bagging_fraction': 0.5476020175063141, 'bagging_freq': 3, 'min_child_samples': 94, 'learning_rate': 0.04066410620031902}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[189]\tvalid_0's auc: 0.868698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082518 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:50:55,106] Trial 40 finished with value: 0.8611028649838974 and parameters: {'lambda_l1': 3.95245280768096e-06, 'lambda_l2': 1.8823012959770708e-06, 'num_leaves': 135, 'feature_fraction': 0.7172768732589545, 'bagging_fraction': 0.6739723409849574, 'bagging_freq': 3, 'min_child_samples': 83, 'learning_rate': 0.010846800517407567}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[26]\tvalid_0's auc: 0.861103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026056 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.865066\n",
            "[200]\tvalid_0's auc: 0.867605\n",
            "[300]\tvalid_0's auc: 0.868705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:51:28,355] Trial 41 finished with value: 0.8689292453998854 and parameters: {'lambda_l1': 0.0002694341467299141, 'lambda_l2': 0.00013917557391274484, 'num_leaves': 226, 'feature_fraction': 0.497682967485062, 'bagging_fraction': 0.562017117658109, 'bagging_freq': 5, 'min_child_samples': 89, 'learning_rate': 0.007425961337317481}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[318]\tvalid_0's auc: 0.868929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017743 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.865854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:51:46,028] Trial 42 finished with value: 0.86765698577263 and parameters: {'lambda_l1': 0.0004956220886196437, 'lambda_l2': 1.0359308087977678e-05, 'num_leaves': 237, 'feature_fraction': 0.401433857768517, 'bagging_fraction': 0.5955887298512936, 'bagging_freq': 5, 'min_child_samples': 84, 'learning_rate': 0.0065942259510689645}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[159]\tvalid_0's auc: 0.867657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060025 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:52:02,499] Trial 43 finished with value: 0.864662509112402 and parameters: {'lambda_l1': 0.0015904269792894968, 'lambda_l2': 3.441052933947886e-06, 'num_leaves': 212, 'feature_fraction': 0.8089984235748346, 'bagging_fraction': 0.6504657658933333, 'bagging_freq': 4, 'min_child_samples': 95, 'learning_rate': 0.011230570771437885}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[143]\tvalid_0's auc: 0.864663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023968 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:52:19,558] Trial 44 finished with value: 0.8650109529975387 and parameters: {'lambda_l1': 0.00024532496173243967, 'lambda_l2': 1.5200624747184324e-07, 'num_leaves': 238, 'feature_fraction': 0.4513041881132663, 'bagging_fraction': 0.6242836342840578, 'bagging_freq': 5, 'min_child_samples': 77, 'learning_rate': 0.0020913858519471624}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[139]\tvalid_0's auc: 0.865011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026428 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.862767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:52:33,034] Trial 45 finished with value: 0.8631102090993238 and parameters: {'lambda_l1': 3.019281430025196e-05, 'lambda_l2': 3.148477002591533e-05, 'num_leaves': 180, 'feature_fraction': 0.5538969341112823, 'bagging_fraction': 0.4225321592649572, 'bagging_freq': 6, 'min_child_samples': 28, 'learning_rate': 0.0049625106099701576}. Best is trial 19 with value: 0.870497435743536.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[110]\tvalid_0's auc: 0.86311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062062 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.865972\n",
            "[200]\tvalid_0's auc: 0.868574\n",
            "[300]\tvalid_0's auc: 0.870142\n",
            "[400]\tvalid_0's auc: 0.871447\n",
            "Early stopping, best iteration is:\n",
            "[475]\tvalid_0's auc: 0.872206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:53:21,260] Trial 46 finished with value: 0.8722062902965301 and parameters: {'lambda_l1': 0.008193037966402892, 'lambda_l2': 0.00012777054448225716, 'num_leaves': 199, 'feature_fraction': 0.6186968713117357, 'bagging_fraction': 0.5062599500755458, 'bagging_freq': 1, 'min_child_samples': 81, 'learning_rate': 0.016358114709472463}. Best is trial 46 with value: 0.8722062902965301.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061079 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.865959\n",
            "[200]\tvalid_0's auc: 0.86859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:53:42,828] Trial 47 finished with value: 0.869084077970732 and parameters: {'lambda_l1': 0.012711877251464927, 'lambda_l2': 0.6261315945927459, 'num_leaves': 215, 'feature_fraction': 0.6297867484207015, 'bagging_fraction': 0.4985410304629786, 'bagging_freq': 1, 'min_child_samples': 80, 'learning_rate': 0.02800434045121421}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[231]\tvalid_0's auc: 0.869084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061437 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.865967\n",
            "[200]\tvalid_0's auc: 0.868141\n",
            "[300]\tvalid_0's auc: 0.870077\n",
            "[400]\tvalid_0's auc: 0.871276\n",
            "Early stopping, best iteration is:\n",
            "[455]\tvalid_0's auc: 0.871598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:54:31,863] Trial 48 finished with value: 0.8715976844365081 and parameters: {'lambda_l1': 0.11316862230510105, 'lambda_l2': 0.00011663066225904116, 'num_leaves': 192, 'feature_fraction': 0.7757195697511962, 'bagging_fraction': 0.4544493477741005, 'bagging_freq': 1, 'min_child_samples': 97, 'learning_rate': 0.015102046285388825}. Best is trial 46 with value: 0.8722062902965301.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059713 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:54:35,771] Trial 49 finished with value: 0.8632761724782353 and parameters: {'lambda_l1': 0.194176843540482, 'lambda_l2': 0.0008042615063602242, 'num_leaves': 194, 'feature_fraction': 0.7577974256836655, 'bagging_fraction': 0.4588990284578483, 'bagging_freq': 1, 'min_child_samples': 96, 'learning_rate': 0.06504468660203065}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[42]\tvalid_0's auc: 0.863276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074450 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.865842\n",
            "[200]\tvalid_0's auc: 0.868086\n",
            "[300]\tvalid_0's auc: 0.870436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:55:09,207] Trial 50 finished with value: 0.8709315992489487 and parameters: {'lambda_l1': 0.7166732440607881, 'lambda_l2': 0.00010175331734197, 'num_leaves': 174, 'feature_fraction': 0.8390450269992464, 'bagging_fraction': 0.40099092466314123, 'bagging_freq': 2, 'min_child_samples': 97, 'learning_rate': 0.015947511190153175}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[337]\tvalid_0's auc: 0.870932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071236 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[100]\tvalid_0's auc: 0.864263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:55:22,602] Trial 51 finished with value: 0.8646481616661156 and parameters: {'lambda_l1': 3.931716383989862, 'lambda_l2': 0.00013266175136903493, 'num_leaves': 172, 'feature_fraction': 0.7913922616051967, 'bagging_fraction': 0.40984963193127916, 'bagging_freq': 2, 'min_child_samples': 97, 'learning_rate': 0.01575757215661838}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[114]\tvalid_0's auc: 0.864648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062096 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:55:34,303] Trial 52 finished with value: 0.865121455196662 and parameters: {'lambda_l1': 0.8840656390829434, 'lambda_l2': 0.006304399887164187, 'num_leaves': 152, 'feature_fraction': 0.8668066381267959, 'bagging_fraction': 0.401230989676935, 'bagging_freq': 1, 'min_child_samples': 91, 'learning_rate': 0.02413013253438402}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[77]\tvalid_0's auc: 0.865121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062994 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.865811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:55:43,001] Trial 53 finished with value: 0.8662875244353437 and parameters: {'lambda_l1': 0.05150086383784404, 'lambda_l2': 0.0004101333303174586, 'num_leaves': 201, 'feature_fraction': 0.7390429460863177, 'bagging_fraction': 0.44328419987741413, 'bagging_freq': 2, 'min_child_samples': 97, 'learning_rate': 0.013341832078539515}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[122]\tvalid_0's auc: 0.866288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119089 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.865133\n",
            "[200]\tvalid_0's auc: 0.868011\n",
            "[300]\tvalid_0's auc: 0.87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:56:16,613] Trial 54 finished with value: 0.8708491995850385 and parameters: {'lambda_l1': 0.8986015282299551, 'lambda_l2': 9.084032984279188e-05, 'num_leaves': 179, 'feature_fraction': 0.8386440882589271, 'bagging_fraction': 0.481993327406088, 'bagging_freq': 1, 'min_child_samples': 93, 'learning_rate': 0.016141067399664855}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[355]\tvalid_0's auc: 0.870849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.097559 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[100]\tvalid_0's auc: 0.863396\n",
            "[200]\tvalid_0's auc: 0.865558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:56:42,065] Trial 55 finished with value: 0.8665145350617044 and parameters: {'lambda_l1': 8.250162232276692, 'lambda_l2': 0.0001423511670584226, 'num_leaves': 128, 'feature_fraction': 0.6966133081922262, 'bagging_fraction': 0.4839672249982873, 'bagging_freq': 1, 'min_child_samples': 99, 'learning_rate': 0.016534051145433562}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[270]\tvalid_0's auc: 0.866515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.080166 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[100]\tvalid_0's auc: 0.865811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:56:49,113] Trial 56 finished with value: 0.8659632225565604 and parameters: {'lambda_l1': 0.5120348082852133, 'lambda_l2': 5.831470760106094, 'num_leaves': 177, 'feature_fraction': 0.8588407530477445, 'bagging_fraction': 0.4348457922254916, 'bagging_freq': 1, 'min_child_samples': 89, 'learning_rate': 0.046925895509076936}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[103]\tvalid_0's auc: 0.865963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062010 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.86578\n",
            "[200]\tvalid_0's auc: 0.868994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:57:17,663] Trial 57 finished with value: 0.8692903078743627 and parameters: {'lambda_l1': 0.1476179018195462, 'lambda_l2': 0.0016383936706357957, 'num_leaves': 186, 'feature_fraction': 0.840753111895859, 'bagging_fraction': 0.5294285917870514, 'bagging_freq': 1, 'min_child_samples': 93, 'learning_rate': 0.03238707832483044}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[226]\tvalid_0's auc: 0.86929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077269 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.864483\n",
            "[200]\tvalid_0's auc: 0.866951\n",
            "[300]\tvalid_0's auc: 0.869464\n",
            "[400]\tvalid_0's auc: 0.870667\n",
            "[500]\tvalid_0's auc: 0.871805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:57:50,897] Trial 58 finished with value: 0.872005212524355 and parameters: {'lambda_l1': 1.1498392653436758, 'lambda_l2': 0.0003159549514333309, 'num_leaves': 83, 'feature_fraction': 0.7797685077389882, 'bagging_fraction': 0.4499571096724051, 'bagging_freq': 2, 'min_child_samples': 100, 'learning_rate': 0.01968912907488861}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[531]\tvalid_0's auc: 0.872005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060960 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863978\n",
            "[200]\tvalid_0's auc: 0.866239\n",
            "[300]\tvalid_0's auc: 0.868442\n",
            "[400]\tvalid_0's auc: 0.869796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:58:21,651] Trial 59 finished with value: 0.8705193805173568 and parameters: {'lambda_l1': 2.4489861118518705, 'lambda_l2': 2.2676259141630268e-05, 'num_leaves': 87, 'feature_fraction': 0.7820601944104525, 'bagging_fraction': 0.45675892697874715, 'bagging_freq': 2, 'min_child_samples': 100, 'learning_rate': 0.019570744145018224}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[467]\tvalid_0's auc: 0.870519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083885 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863606\n",
            "[200]\tvalid_0's auc: 0.866355\n",
            "[300]\tvalid_0's auc: 0.868382\n",
            "[400]\tvalid_0's auc: 0.86982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:58:40,966] Trial 60 finished with value: 0.8708960853588608 and parameters: {'lambda_l1': 2.5050921686644583, 'lambda_l2': 3.1057514919209706e-05, 'num_leaves': 34, 'feature_fraction': 0.7778377936846324, 'bagging_fraction': 0.4495912493580309, 'bagging_freq': 2, 'min_child_samples': 96, 'learning_rate': 0.0254233674303444}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[500]\tvalid_0's auc: 0.870868\n",
            "Early stopping, best iteration is:\n",
            "[490]\tvalid_0's auc: 0.870896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069443 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863331\n",
            "[200]\tvalid_0's auc: 0.865986\n",
            "[300]\tvalid_0's auc: 0.867946\n",
            "[400]\tvalid_0's auc: 0.869152\n",
            "[500]\tvalid_0's auc: 0.870256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:59:00,011] Trial 61 finished with value: 0.8706833877394053 and parameters: {'lambda_l1': 2.098111994617845, 'lambda_l2': 2.7656928121795134e-05, 'num_leaves': 27, 'feature_fraction': 0.772444650699744, 'bagging_fraction': 0.45022448725294606, 'bagging_freq': 2, 'min_child_samples': 97, 'learning_rate': 0.024883153841916507}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[539]\tvalid_0's auc: 0.870683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059703 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863788\n",
            "[200]\tvalid_0's auc: 0.866736\n",
            "[300]\tvalid_0's auc: 0.868749\n",
            "[400]\tvalid_0's auc: 0.86979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:59:15,184] Trial 62 finished with value: 0.8703784270172097 and parameters: {'lambda_l1': 1.187700251938519, 'lambda_l2': 8.28150634396447e-05, 'num_leaves': 18, 'feature_fraction': 0.8115322229401147, 'bagging_fraction': 0.4275682030618384, 'bagging_freq': 2, 'min_child_samples': 97, 'learning_rate': 0.0320836114872948}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[443]\tvalid_0's auc: 0.870378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061627 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863506\n",
            "[200]\tvalid_0's auc: 0.866083\n",
            "[300]\tvalid_0's auc: 0.868475\n",
            "[400]\tvalid_0's auc: 0.869811\n",
            "[500]\tvalid_0's auc: 0.870998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 02:59:33,695] Trial 63 finished with value: 0.871121194931369 and parameters: {'lambda_l1': 3.456911047438564, 'lambda_l2': 0.0003821053636441385, 'num_leaves': 26, 'feature_fraction': 0.8356373104344397, 'bagging_fraction': 0.5055785720944047, 'bagging_freq': 2, 'min_child_samples': 87, 'learning_rate': 0.026138965096105242}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[509]\tvalid_0's auc: 0.871121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061317 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.862733\n",
            "[200]\tvalid_0's auc: 0.864658\n",
            "[300]\tvalid_0's auc: 0.866787\n",
            "[400]\tvalid_0's auc: 0.868223\n",
            "[500]\tvalid_0's auc: 0.869304\n",
            "[600]\tvalid_0's auc: 0.870299\n",
            "[700]\tvalid_0's auc: 0.871133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:00:06,891] Trial 64 finished with value: 0.8713634002127981 and parameters: {'lambda_l1': 4.918108403384346, 'lambda_l2': 0.0004022915493333351, 'num_leaves': 43, 'feature_fraction': 0.8954573754724341, 'bagging_fraction': 0.4841651535699682, 'bagging_freq': 1, 'min_child_samples': 89, 'learning_rate': 0.018023343456152276}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[744]\tvalid_0's auc: 0.871363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059661 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:00:09,275] Trial 65 finished with value: 0.8621372793554072 and parameters: {'lambda_l1': 5.163510323746461, 'lambda_l2': 0.0004394123811932626, 'num_leaves': 42, 'feature_fraction': 0.921657604874428, 'bagging_fraction': 0.5078176567703404, 'bagging_freq': 2, 'min_child_samples': 87, 'learning_rate': 0.022058356734695743}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[47]\tvalid_0's auc: 0.862137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.136350 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.865168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:00:18,844] Trial 66 finished with value: 0.8658816701014325 and parameters: {'lambda_l1': 0.10861002058894025, 'lambda_l2': 0.0002500199596447792, 'num_leaves': 34, 'feature_fraction': 0.8869264203807177, 'bagging_fraction': 0.4927318166239776, 'bagging_freq': 1, 'min_child_samples': 87, 'learning_rate': 0.08458737474916846}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[111]\tvalid_0's auc: 0.865882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061975 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.862525\n",
            "[200]\tvalid_0's auc: 0.865056\n",
            "[300]\tvalid_0's auc: 0.866541\n",
            "[400]\tvalid_0's auc: 0.86748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:00:26,265] Trial 67 finished with value: 0.8675328386906006 and parameters: {'lambda_l1': 0.3856383813073799, 'lambda_l2': 0.0019472106358855105, 'num_leaves': 9, 'feature_fraction': 0.83096029599265, 'bagging_fraction': 0.5416024977996087, 'bagging_freq': 1, 'min_child_samples': 80, 'learning_rate': 0.035218988089679486}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[406]\tvalid_0's auc: 0.867533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.150660 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.864926\n",
            "[200]\tvalid_0's auc: 0.86691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:00:41,140] Trial 68 finished with value: 0.8680870303280286 and parameters: {'lambda_l1': 9.557125981638588, 'lambda_l2': 0.00467682749390766, 'num_leaves': 54, 'feature_fraction': 0.9433992926411126, 'bagging_fraction': 0.518165189360182, 'bagging_freq': 2, 'min_child_samples': 75, 'learning_rate': 0.04884271825398799}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[279]\tvalid_0's auc: 0.868087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059765 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.864178\n",
            "[200]\tvalid_0's auc: 0.866807\n",
            "[300]\tvalid_0's auc: 0.869051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:00:59,162] Trial 69 finished with value: 0.8693042420480727 and parameters: {'lambda_l1': 2.877020883188519, 'lambda_l2': 0.00020650825883628782, 'num_leaves': 68, 'feature_fraction': 0.7967505777103198, 'bagging_fraction': 0.4181040490637545, 'bagging_freq': 1, 'min_child_samples': 90, 'learning_rate': 0.025796280057120216}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[313]\tvalid_0's auc: 0.869304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069927 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863508\n",
            "[200]\tvalid_0's auc: 0.865653\n",
            "[300]\tvalid_0's auc: 0.867631\n",
            "[400]\tvalid_0's auc: 0.86915\n",
            "[500]\tvalid_0's auc: 0.870341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:01:27,130] Trial 70 finished with value: 0.8707167801635997 and parameters: {'lambda_l1': 1.0877148326777053, 'lambda_l2': 4.2605101610394973e-05, 'num_leaves': 51, 'feature_fraction': 0.7590520672761284, 'bagging_fraction': 0.4386090657406799, 'bagging_freq': 2, 'min_child_samples': 82, 'learning_rate': 0.01899784413065809}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[535]\tvalid_0's auc: 0.870717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063615 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863551\n",
            "[200]\tvalid_0's auc: 0.865852\n",
            "[300]\tvalid_0's auc: 0.867316\n",
            "[400]\tvalid_0's auc: 0.869375\n",
            "[500]\tvalid_0's auc: 0.8706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:01:59,515] Trial 71 finished with value: 0.871020521731694 and parameters: {'lambda_l1': 0.6189807888176728, 'lambda_l2': 7.584344202798259e-05, 'num_leaves': 80, 'feature_fraction': 0.8369930916683324, 'bagging_fraction': 0.4762514430968999, 'bagging_freq': 1, 'min_child_samples': 92, 'learning_rate': 0.013551038833668008}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[547]\tvalid_0's auc: 0.871021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061845 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.862678\n",
            "[200]\tvalid_0's auc: 0.864552\n",
            "[300]\tvalid_0's auc: 0.865921\n",
            "[400]\tvalid_0's auc: 0.867246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:02:18,618] Trial 72 finished with value: 0.8681938612890959 and parameters: {'lambda_l1': 0.22624434517744244, 'lambda_l2': 0.00047696911977400256, 'num_leaves': 33, 'feature_fraction': 0.8545555296883157, 'bagging_fraction': 0.46974360290388295, 'bagging_freq': 1, 'min_child_samples': 93, 'learning_rate': 0.013455137236828955}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[500]\tvalid_0's auc: 0.868194\n",
            "Early stopping, best iteration is:\n",
            "[490]\tvalid_0's auc: 0.868194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065763 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:02:21,697] Trial 73 finished with value: 0.8617504665554656 and parameters: {'lambda_l1': 0.5846848383065534, 'lambda_l2': 5.858036237438604e-05, 'num_leaves': 18, 'feature_fraction': 0.8936194488333062, 'bagging_fraction': 0.47938681341863487, 'bagging_freq': 2, 'min_child_samples': 86, 'learning_rate': 0.0094300526315366}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[87]\tvalid_0's auc: 0.86175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.136025 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863964\n",
            "[200]\tvalid_0's auc: 0.866247\n",
            "[300]\tvalid_0's auc: 0.868592\n",
            "[400]\tvalid_0's auc: 0.870213\n",
            "[500]\tvalid_0's auc: 0.87111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:02:51,441] Trial 74 finished with value: 0.8713540533646892 and parameters: {'lambda_l1': 0.07363101976081703, 'lambda_l2': 0.001307333151516795, 'num_leaves': 72, 'feature_fraction': 0.8205642119604397, 'bagging_fraction': 0.46943396763482936, 'bagging_freq': 1, 'min_child_samples': 90, 'learning_rate': 0.017747556445303823}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[524]\tvalid_0's auc: 0.871354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061666 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.864116\n",
            "[200]\tvalid_0's auc: 0.866707\n",
            "[300]\tvalid_0's auc: 0.868998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:03:09,894] Trial 75 finished with value: 0.8695693632938778 and parameters: {'lambda_l1': 0.0764725925187891, 'lambda_l2': 0.0010472534199417805, 'num_leaves': 77, 'feature_fraction': 0.8241518735828731, 'bagging_fraction': 0.40079362944575536, 'bagging_freq': 1, 'min_child_samples': 70, 'learning_rate': 0.01740072381340541}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[321]\tvalid_0's auc: 0.869569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060209 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:03:11,796] Trial 76 finished with value: 0.8613838800042134 and parameters: {'lambda_l1': 0.030346346415847554, 'lambda_l2': 0.00025662384488211987, 'num_leaves': 77, 'feature_fraction': 0.8749697896740873, 'bagging_fraction': 0.5131938004327017, 'bagging_freq': 1, 'min_child_samples': 90, 'learning_rate': 0.01139564443411338}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[14]\tvalid_0's auc: 0.861384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.140114 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:03:26,062] Trial 77 finished with value: 0.865258716795124 and parameters: {'lambda_l1': 1.3658329084410297, 'lambda_l2': 0.01004027366749518, 'num_leaves': 96, 'feature_fraction': 0.7300030150475428, 'bagging_fraction': 0.4678876693700204, 'bagging_freq': 1, 'min_child_samples': 32, 'learning_rate': 0.014381564210996883}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[178]\tvalid_0's auc: 0.865259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060280 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863755\n",
            "[200]\tvalid_0's auc: 0.866717\n",
            "[300]\tvalid_0's auc: 0.869001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:03:55,094] Trial 78 finished with value: 0.8695699349876089 and parameters: {'lambda_l1': 0.012954829095644054, 'lambda_l2': 0.0028577564781950052, 'num_leaves': 112, 'feature_fraction': 0.8493560192790227, 'bagging_fraction': 0.5311727555174237, 'bagging_freq': 1, 'min_child_samples': 77, 'learning_rate': 0.021400107799408635}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[339]\tvalid_0's auc: 0.86957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059364 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.862683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:03:59,327] Trial 79 finished with value: 0.8627433125936395 and parameters: {'lambda_l1': 0.23974579234871726, 'lambda_l2': 0.0641694940665981, 'num_leaves': 57, 'feature_fraction': 0.9132903002617412, 'bagging_fraction': 0.5021503362431504, 'bagging_freq': 1, 'min_child_samples': 82, 'learning_rate': 0.008677966064306512}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[105]\tvalid_0's auc: 0.862743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059919 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.864821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:04:13,074] Trial 80 finished with value: 0.8674250158753494 and parameters: {'lambda_l1': 0.022086478989753182, 'lambda_l2': 0.00010105387575234881, 'num_leaves': 80, 'feature_fraction': 0.8019750066259389, 'bagging_fraction': 0.43195565069758934, 'bagging_freq': 2, 'min_child_samples': 92, 'learning_rate': 0.04066706239917992}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[178]\tvalid_0's auc: 0.867425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061297 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.864224\n",
            "[200]\tvalid_0's auc: 0.867227\n",
            "[300]\tvalid_0's auc: 0.869214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:04:29,343] Trial 81 finished with value: 0.8695000643706478 and parameters: {'lambda_l1': 4.220285509318142, 'lambda_l2': 0.0005740864411512667, 'num_leaves': 47, 'feature_fraction': 0.8169473118524562, 'bagging_fraction': 0.44712560001719515, 'bagging_freq': 2, 'min_child_samples': 96, 'learning_rate': 0.02855442933701541}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[312]\tvalid_0's auc: 0.8695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059695 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:04:31,205] Trial 82 finished with value: 0.8610802520860777 and parameters: {'lambda_l1': 0.6198399379595878, 'lambda_l2': 1.2626336145785427e-05, 'num_leaves': 40, 'feature_fraction': 0.7523091308790145, 'bagging_fraction': 0.4690859950409538, 'bagging_freq': 1, 'min_child_samples': 88, 'learning_rate': 0.012459767716977507}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[21]\tvalid_0's auc: 0.86108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058985 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.86417\n",
            "[200]\tvalid_0's auc: 0.866389\n",
            "[300]\tvalid_0's auc: 0.868543\n",
            "[400]\tvalid_0's auc: 0.869866\n",
            "[500]\tvalid_0's auc: 0.870914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:05:01,180] Trial 83 finished with value: 0.8710990090818785 and parameters: {'lambda_l1': 1.987401813940144, 'lambda_l2': 0.0014592735316997629, 'num_leaves': 62, 'feature_fraction': 0.7735239593800528, 'bagging_fraction': 0.4215369334124443, 'bagging_freq': 2, 'min_child_samples': 98, 'learning_rate': 0.01915406551553357}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[524]\tvalid_0's auc: 0.871099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059470 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.86437\n",
            "[200]\tvalid_0's auc: 0.866804\n",
            "[300]\tvalid_0's auc: 0.86891\n",
            "[400]\tvalid_0's auc: 0.870629\n",
            "[500]\tvalid_0's auc: 0.871864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:05:24,065] Trial 84 finished with value: 0.8719373600551432 and parameters: {'lambda_l1': 1.6077600956947498, 'lambda_l2': 0.0015090317821651953, 'num_leaves': 63, 'feature_fraction': 0.706724991662737, 'bagging_fraction': 0.41540534542434226, 'bagging_freq': 1, 'min_child_samples': 99, 'learning_rate': 0.018265381333850392}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[512]\tvalid_0's auc: 0.871937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094385 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:05:33,807] Trial 85 finished with value: 0.8628853130509806 and parameters: {'lambda_l1': 1.5877955845918839, 'lambda_l2': 0.0013706035786905909, 'num_leaves': 86, 'feature_fraction': 0.6002758758264793, 'bagging_fraction': 0.4173927041644091, 'bagging_freq': 1, 'min_child_samples': 100, 'learning_rate': 0.018360032444313033}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[49]\tvalid_0's auc: 0.862885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058961 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:05:38,415] Trial 86 finished with value: 0.8636098763081378 and parameters: {'lambda_l1': 6.295103102968506, 'lambda_l2': 0.0006622989977200503, 'num_leaves': 68, 'feature_fraction': 0.6680465246653838, 'bagging_fraction': 0.48504397138770394, 'bagging_freq': 1, 'min_child_samples': 94, 'learning_rate': 0.01078438607151452}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[116]\tvalid_0's auc: 0.86361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060001 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.864164\n",
            "[200]\tvalid_0's auc: 0.866438\n",
            "[300]\tvalid_0's auc: 0.867978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:05:56,405] Trial 87 finished with value: 0.8684070479477672 and parameters: {'lambda_l1': 0.006803510044791786, 'lambda_l2': 0.0054893238626803975, 'num_leaves': 64, 'feature_fraction': 0.7049150604348864, 'bagging_fraction': 0.5473670377733122, 'bagging_freq': 1, 'min_child_samples': 85, 'learning_rate': 0.021797494816730878}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[326]\tvalid_0's auc: 0.868407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059365 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863769\n",
            "[200]\tvalid_0's auc: 0.865578\n",
            "[300]\tvalid_0's auc: 0.867394\n",
            "[400]\tvalid_0's auc: 0.86923\n",
            "[500]\tvalid_0's auc: 0.870412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:06:26,452] Trial 88 finished with value: 0.871241567457198 and parameters: {'lambda_l1': 0.3489070010293789, 'lambda_l2': 0.002260315679074963, 'num_leaves': 57, 'feature_fraction': 0.7384452082673777, 'bagging_fraction': 0.4272992757998126, 'bagging_freq': 1, 'min_child_samples': 91, 'learning_rate': 0.014749306156115772}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[575]\tvalid_0's auc: 0.871242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060206 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863333\n",
            "[200]\tvalid_0's auc: 0.865599\n",
            "[300]\tvalid_0's auc: 0.867528\n",
            "[400]\tvalid_0's auc: 0.868941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:06:47,030] Trial 89 finished with value: 0.8697209172356161 and parameters: {'lambda_l1': 0.06243725754577628, 'lambda_l2': 0.0023704343494098702, 'num_leaves': 60, 'feature_fraction': 0.7298271714509406, 'bagging_fraction': 0.42089446766123345, 'bagging_freq': 1, 'min_child_samples': 98, 'learning_rate': 0.015082882292294177}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[460]\tvalid_0's auc: 0.869721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062632 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863303\n",
            "[200]\tvalid_0's auc: 0.866048\n",
            "[300]\tvalid_0's auc: 0.867874\n",
            "[400]\tvalid_0's auc: 0.869486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:07:13,189] Trial 90 finished with value: 0.8699881806109436 and parameters: {'lambda_l1': 0.3696763860292849, 'lambda_l2': 0.008827331232443635, 'num_leaves': 51, 'feature_fraction': 0.7081041700613453, 'bagging_fraction': 0.43441995877181233, 'bagging_freq': 1, 'min_child_samples': 89, 'learning_rate': 0.019304865751696678}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[449]\tvalid_0's auc: 0.869988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059685 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.864159\n",
            "[200]\tvalid_0's auc: 0.866181\n",
            "[300]\tvalid_0's auc: 0.867526\n",
            "[400]\tvalid_0's auc: 0.869135\n",
            "[500]\tvalid_0's auc: 0.870204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:07:48,114] Trial 91 finished with value: 0.8709557412553021 and parameters: {'lambda_l1': 0.1028356295129053, 'lambda_l2': 0.00030383155418093347, 'num_leaves': 94, 'feature_fraction': 0.7437204601074255, 'bagging_fraction': 0.46771646156318153, 'bagging_freq': 1, 'min_child_samples': 92, 'learning_rate': 0.013487234691163728}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[567]\tvalid_0's auc: 0.870956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059189 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863619\n",
            "[200]\tvalid_0's auc: 0.865612\n",
            "[300]\tvalid_0's auc: 0.868023\n",
            "[400]\tvalid_0's auc: 0.869514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:08:10,797] Trial 92 finished with value: 0.8705693864991328 and parameters: {'lambda_l1': 1.5550886235649821, 'lambda_l2': 0.017852875377734265, 'num_leaves': 69, 'feature_fraction': 0.7676601045145032, 'bagging_fraction': 0.45840082569946317, 'bagging_freq': 1, 'min_child_samples': 95, 'learning_rate': 0.017131099943233218}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[472]\tvalid_0's auc: 0.870569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059661 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:08:20,680] Trial 93 finished with value: 0.862708329070025 and parameters: {'lambda_l1': 3.419522619624815, 'lambda_l2': 0.0013295076391712606, 'num_leaves': 80, 'feature_fraction': 0.6837931407496752, 'bagging_fraction': 0.48917121057981383, 'bagging_freq': 1, 'min_child_samples': 91, 'learning_rate': 0.012289764113771693}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[61]\tvalid_0's auc: 0.862708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060175 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:08:22,827] Trial 94 finished with value: 0.8606124240853577 and parameters: {'lambda_l1': 0.1808644779103197, 'lambda_l2': 0.00016546139261136615, 'num_leaves': 106, 'feature_fraction': 0.7871748951022636, 'bagging_fraction': 0.9829533810309831, 'bagging_freq': 1, 'min_child_samples': 100, 'learning_rate': 0.010193267050187705}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[17]\tvalid_0's auc: 0.860612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059615 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:08:24,731] Trial 95 finished with value: 0.861795668243538 and parameters: {'lambda_l1': 0.2984948854194213, 'lambda_l2': 0.000799142511977209, 'num_leaves': 23, 'feature_fraction': 0.8024257313524827, 'bagging_fraction': 0.44363138705162064, 'bagging_freq': 2, 'min_child_samples': 94, 'learning_rate': 0.023229103739538265}. Best is trial 46 with value: 0.8722062902965301.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[31]\tvalid_0's auc: 0.861796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096482 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863717\n",
            "[200]\tvalid_0's auc: 0.866147\n",
            "[300]\tvalid_0's auc: 0.868235\n",
            "[400]\tvalid_0's auc: 0.869918\n",
            "[500]\tvalid_0's auc: 0.870909\n",
            "[600]\tvalid_0's auc: 0.872086\n",
            "[700]\tvalid_0's auc: 0.872728\n",
            "Early stopping, best iteration is:\n",
            "[719]\tvalid_0's auc: 0.872867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:09:01,129] Trial 96 finished with value: 0.8728667205376655 and parameters: {'lambda_l1': 0.039076152897457965, 'lambda_l2': 0.003960763919615024, 'num_leaves': 73, 'feature_fraction': 0.7234039183517194, 'bagging_fraction': 0.41126972243069154, 'bagging_freq': 1, 'min_child_samples': 86, 'learning_rate': 0.01462750265655845}. Best is trial 96 with value: 0.8728667205376655.\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.132434 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:09:12,266] Trial 97 finished with value: 0.8646096584377232 and parameters: {'lambda_l1': 0.019945998210254483, 'lambda_l2': 0.003741146966968802, 'num_leaves': 48, 'feature_fraction': 0.7269576612080593, 'bagging_fraction': 0.41964416055066217, 'bagging_freq': 2, 'min_child_samples': 23, 'learning_rate': 0.0206030993485737}. Best is trial 96 with value: 0.8728667205376655.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[168]\tvalid_0's auc: 0.86461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060456 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:09:15,760] Trial 98 finished with value: 0.8636294516525191 and parameters: {'lambda_l1': 0.1128482705688077, 'lambda_l2': 0.013964868316593411, 'num_leaves': 73, 'feature_fraction': 0.6949794529871265, 'bagging_fraction': 0.9482736821360253, 'bagging_freq': 3, 'min_child_samples': 86, 'learning_rate': 0.029692965389442508}. Best is trial 96 with value: 0.8728667205376655.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[66]\tvalid_0's auc: 0.863629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060017 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-09 03:09:17,770] Trial 99 finished with value: 0.8599686280654332 and parameters: {'lambda_l1': 5.686949986002265, 'lambda_l2': 0.03688713914956788, 'num_leaves': 58, 'feature_fraction': 0.6599363015665128, 'bagging_fraction': 0.45398937320407806, 'bagging_freq': 1, 'min_child_samples': 50, 'learning_rate': 0.17788538150639613}. Best is trial 96 with value: 0.8728667205376655.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping, best iteration is:\n",
            "[23]\tvalid_0's auc: 0.859969\n",
            "Best trial: {'lambda_l1': 0.039076152897457965, 'lambda_l2': 0.003960763919615024, 'num_leaves': 73, 'feature_fraction': 0.7234039183517194, 'bagging_fraction': 0.41126972243069154, 'bagging_freq': 1, 'min_child_samples': 86, 'learning_rate': 0.01462750265655845}\n",
            "Best score: 0.8728667205376655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Testing Final Model"
      ],
      "metadata": {
        "id": "yucNwImxSnEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the best model\n",
        "best_params = study.best_trial.params\n",
        "best_params.update({'metric': 'auc', 'objective': 'binary'})\n",
        "final_model = lgb.train(best_params, lgb.Dataset(X_train, label=y_train), valid_sets=[lgb.Dataset(X_val, label=y_val)],\n",
        "                        callbacks=[lgb.early_stopping(10), lgb.log_evaluation(100)])\n",
        "\n",
        "#Testing prediction\n",
        "test_preds = final_model.predict(X_test, num_iteration=final_model.best_iteration)\n",
        "test_roc_auc = roc_auc_score(y_test, test_preds)\n",
        "print(f'\\nTest ROC-AUC: {test_roc_auc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng_UhbhUSpwN",
        "outputId": "90750504-3bcc-4b81-d7ff-304885d7696e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11996, number of negative: 108004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115508 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 48450\n",
            "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 190\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099967 -> initscore=-2.197595\n",
            "[LightGBM] [Info] Start training from score -2.197595\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[100]\tvalid_0's auc: 0.863717\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[98]\tvalid_0's auc: 0.863744\n",
            "\n",
            "Test ROC-AUC: 0.8618018490745643\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}